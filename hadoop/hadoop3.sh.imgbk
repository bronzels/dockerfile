HADOOPREV=3.2.1
wget -c http://archive.apache.org/dist/hadoop/common/hadoop-${HADOOPREV}/hadoop-${HADOOPREV}-src.tar.gz
wget -c http://archive.apache.org/dist/hadoop/common/hadoop-${HADOOPREV}/hadoop-${HADOOPREV}.tar.gz

rm -rf helm-hadoop-3
git clone https://github.com/chenseanxy/helm-hadoop-3.git
rm -rf helm-hadoop-3.bk
cp -r helm-hadoop-3 helm-hadoop-3.bk
if [[ "$OSTYPE" == "darwin"* ]]; then
    echo "Mac detected."
    #mac
    HDPHOME=/Volumes/data/workspace/cluster-sh-k8s/hadoop/helm-hadoop-3
    SED=gsed
else
    echo "Assuming linux by default."
    #linux
    HDPHOME=~/helm-hadoop-3
    SED=sed
fi

cd $HDPHOME

cd image

docker images|grep hadoop
docker images|grep hadoop|awk '{print $3}'|xargs docker rmi -f
#docker
ansible all -m shell -a"docker images|grep hadoop"
ansible all -m shell -a"docker images|grep hadoop|awk '{print \$3}'|xargs docker rmi -f"
#containerd
ansible all -m shell -a"crictl images|grep hadoop"
ansible all -m shell -a"crictl images|grep hadoop|awk '{print \$3}'|xargs crictl rmi"

file=Dockerfile
cp ../../helm-hadoop-3.bk/image/${file} ${file}.template
$SED -i 's/HADOOP_PREFIX/HADOOP_HOME/g' ${file}.template
$SED -i '/    YARN_CONF_DIR/a\    YARN_HOME=/usr/local/hadoop \\' ${file}.template

cp ${file}.template ${file}
#$SED -i 's@FROM java:8-jre@FROM anapsix\/alpine-java@g' ${file}
#替换为alpine以后，datanode/nodemanager不能启动

file=Makefile
cp ../../helm-hadoop-3.bk/image/${file} ${file}
$SED -i "s@HADOOP_30_VERSION = 3.2.1@HADOOP_30_VERSION = ${HADOOPREV}@g" ${file}

cp ../../hadoop-3.2.1* ./
make
#helm install错误kubernetes Error: create: failed to create: Request entity too large: limit is 3145728
#rm hadoop-${HADOOPREV}.tar.gz

docker tag hadoop:${HADOOPREV}-nolib harbor.my.org:1080/chenseanxy/hadoop:${HADOOPREV}-nolib
docker push harbor.my.org:1080/chenseanxy/hadoop:${HADOOPREV}-nolib

cp ../../../../dockerfile/image/sources-16.04.list sources.list
file=Dockerfile
cp ${file}.template ${file}
$SED -i 's@FROM java:8-jre@FROM paulosalgado\/oracle-java8-ubuntu-16@g' ${file}

#cp ~/source.list.ubuntu.16.04 source.list
#COPY ./source.list /etc/apt
cat << \EOF >> ${file}

COPY sources.list /etc/apt
RUN apt-get update
RUN apt-get install -y openssh-server
RUN sed -i 's@PermitRootLogin prohibit-password@PermitRootLogin yes@g' /etc/ssh/sshd_config
RUN sed -i 's@#PasswordAuthentication yes@PasswordAuthentication yes@g' /etc/ssh/sshd_config
RUN usermod --password $(echo root | openssl passwd -1 -stdin) root

EXPOSE 22
EOF

cp Makefile Makefile-ubu16ssh
$SED -i 's@$(DOCKER) build -t hadoop@$(DOCKER) build -t hadoop-ubu16ssh@g' Makefile-ubu16ssh
make -f Makefile-ubu16ssh

docker tag hadoop-ubu16ssh:${HADOOPREV}-nolib harbor.my.org:1080/chenseanxy/hadoop-ubu16ssh:${HADOOPREV}-nolib
docker push harbor.my.org:1080/chenseanxy/hadoop-ubu16ssh:${HADOOPREV}-nolib

rm -f hadoop-${HADOOPREV}*

cd $HDPHOME
file=values.yaml
cp ${HDPHOME}.bk/$file $file
$SED -i 's@repository: chenseanxy/hadoop@repository: harbor.my.org:1080/chenseanxy/hadoop@g' ${file}
$SED -i "s@tag: 3.2.1-nolib@tag: ${HADOOPREV}-nolib@g" ${file}
$SED -i "s@hadoopVersion: 3.2.1@hadoopVersion: ${HADOOPREV}@g" ${file}
$SED -i 's@pullPolicy: IfNotPresent@pullPolicy: Always@g' ${file}

kubectl apply -f - <<EOF
apiVersion: storage.k8s.io/v1
kind: StorageClass
metadata:
   name: hdfs-local-storage-dn
provisioner: kubernetes.io/no-provisioner
reclaimPolicy: Retain
volumeBindingMode: WaitForFirstConsumer
EOF
kubectl apply -f - <<EOF
apiVersion: storage.k8s.io/v1
kind: StorageClass
metadata:
   name: hdfs-local-storage-nn
provisioner: kubernetes.io/no-provisioner
reclaimPolicy: Retain
volumeBindingMode: WaitForFirstConsumer
EOF
kubectl get sc

ansible all -m shell -a"rm -rf /data0/hdfs"
ansible all -m shell -a"mkdir -p /data0/hdfs/pvdn"

mkdir pvs
cat << \EOF > hdfs-pv-template.yaml
apiVersion: v1
kind: PersistentVolume
metadata:
   name: myhost-hdfs-pvdn
   labels:
     app: hdfs
spec:
   capacity:
      storage: 80Gi
   volumeMode: Filesystem
   accessModes:
   - ReadWriteOnce
   persistentVolumeReclaimPolicy: Retain
   storageClassName: hdfs-local-storage-dn
   local:
      path: /data0/hdfs/pvdn
   nodeAffinity:
      required:
         nodeSelectorTerms:
         - matchExpressions:
            - key: kubernetes.io/hostname
              operator: In
              values:
              - myhost
EOF

sudo ssh dtpct mkdir -p /data0/hdfs/pvnn
cat << \EOF > hdfs-pv-nn.yaml
apiVersion: v1
kind: PersistentVolume
metadata:
   name: dtpct-hdfs-pvnn
   labels:
     app: hdfs
spec:
   capacity:
      storage: 20Gi
   volumeMode: Filesystem
   accessModes:
   - ReadWriteOnce
   persistentVolumeReclaimPolicy: Retain
   storageClassName: hdfs-local-storage-nn
   local:
      path: /data0/hdfs/pvnn
   nodeAffinity:
      required:
         nodeSelectorTerms:
         - matchExpressions:
            - key: kubernetes.io/hostname
              operator: In
              values:
              - dtpct
EOF
kubectl apply -f hdfs-pv-nn.yaml
kubectl delete -f hdfs-pv-nn.yaml

for myhost in {dtpct,mdubu,mdlapubu}
do
  echo "myhost:${myhost}"
  cp hdfs-pv-template.yaml pvs/hdfs-pv-${myhost}.yaml
  sed -i "" "s/myhost/${myhost}/g" pvs/hdfs-pv-${myhost}.yaml
  cat pvs/hdfs-pv-${myhost}.yaml
done

kubectl apply -f pvs/
kubectl delete -f pvs/
kubectl get pv

find $HDPHOME -name "*.yaml" | xargs grep "apps/v1beta1"
find $HDPHOME -name "*.yaml" | xargs $SED -i 's@apps/v1beta1@apps/v1@g'

$SED -i '/  serviceName:/i\  selector:\n    matchLabels:\n      app: {{ include "hadoop.name" . }}' templates/yarn-nm-statefulset.yaml
$SED -i '/  serviceName:/i\  selector:\n    matchLabels:\n      app: {{ include "hadoop.name" . }}' templates/hdfs-dn-statefulset.yaml
$SED -i '/  serviceName:/i\  selector:\n    matchLabels:\n      app: {{ include "hadoop.name" . }}' templates/yarn-rm-statefulset.yaml
$SED -i '/  serviceName:/i\  selector:\n    matchLabels:\n      app: {{ include "hadoop.name" . }}' templates/hdfs-nn-statefulset.yaml

file=templates/hadoop-configmap.yaml
cp ../helm-hadoop-3.bk/$file $file
#$SED -i 's@@@g' $file

rm -f templates/hdfs-dn-pvc.yaml

file=templates/hdfs-dn-statefulset.yaml
cp ../helm-hadoop-3.bk/$file $file
cat << \EOF > templates/hdfs-dn-statefulset.yaml
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: {{ include "hadoop.fullname" . }}-hdfs-dn
  annotations:
    checksum/config: {{ include (print $.Template.BasePath "/hadoop-configmap.yaml") . | sha256sum }}
  labels:
    app: {{ include "hadoop.name" . }}
    chart: {{ include "hadoop.chart" . }}
    release: {{ .Release.Name }}
    component: hdfs-dn
spec:
  selector:
      matchLabels:
        app: {{ include "hadoop.name" . }}
  serviceName: {{ include "hadoop.fullname" . }}-hdfs-dn
  replicas: {{ .Values.hdfs.dataNode.replicas }}
  template:
    metadata:
      labels:
        app: {{ include "hadoop.name" . }}
        release: {{ .Release.Name }}
        component: hdfs-dn
    spec:
      affinity:
        podAntiAffinity:
        {{- if eq .Values.antiAffinity "hard" }}
          requiredDuringSchedulingIgnoredDuringExecution:
          - topologyKey: "kubernetes.io/hostname"
            labelSelector:
              matchLabels:
                app:  {{ include "hadoop.name" . }}
                release: {{ .Release.Name | quote }}
                component: hdfs-dn
        {{- else if eq .Values.antiAffinity "soft" }}
          preferredDuringSchedulingIgnoredDuringExecution:
          - weight: 5
            podAffinityTerm:
              topologyKey: "kubernetes.io/hostname"
              labelSelector:
                matchLabels:
                  app:  {{ include "hadoop.name" . }}
                  release: {{ .Release.Name | quote }}
                  component: hdfs-dn
        {{- end }}
      terminationGracePeriodSeconds: 0
      containers:
      - name: hdfs-dn
        image: "{{ .Values.image.repository }}:{{ .Values.image.tag }}"
        imagePullPolicy: {{ .Values.image.pullPolicy | quote }}
        command:
           - "/bin/bash"
           - "/tmp/hadoop-config/bootstrap.sh"
           - "-d"
        resources:
{{ toYaml .Values.hdfs.dataNode.resources | indent 10 }}
        readinessProbe:
          httpGet:
            path: /
            port: 9864
          initialDelaySeconds: 5
          timeoutSeconds: 2
        livenessProbe:
          httpGet:
            path: /
            port: 9864
          initialDelaySeconds: 10
          timeoutSeconds: 2
        volumeMounts:
        - name: hadoop-config
          mountPath: /tmp/hadoop-config
        - name: dfs
          mountPath: /root/hdfs/datanode
      volumes:
      - name: hadoop-config
        configMap:
          name: {{ include "hadoop.fullname" . }}
      {{- if not .Values.persistence.dataNode.enabled }}
      - name: dfs
        emptyDir: {}
      {{- end }}
  {{- if .Values.persistence.dataNode.enabled }}
  volumeClaimTemplates:
    - metadata:
        name: dfs
      spec:
        accessModes:
          - {{ .Values.persistence.dataNode.accessMode | quote }}
        resources:
          requests:
            storage: {{ .Values.persistence.dataNode.size | quote }}
      {{- if .Values.persistence.dataNode.storageClass }}
        {{- if (eq "-" .Values.persistence.dataNode.storageClass) }}
        storageClassName: ""
        {{- else }}
        storageClassName: "{{ .Values.persistence.dataNode.storageClass }}"
        {{- end }}
      {{- end }}
  {{- end }}
EOF


