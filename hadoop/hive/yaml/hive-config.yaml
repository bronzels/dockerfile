apiVersion: v1
kind: ConfigMap
metadata:
  name: hive-custom-config-cm
  labels:
    app: hive
data:
  bootstrap.sh: |-
    #!/bin/bash
    # from hadoop boot strap
    # Directory to find config artifacts
    CONFIG_DIR="/tmp/hadoop-config"

    # Copy config files from volume mount

    #for f in slaves core-site.xml hdfs-site.xml mapred-site.xml yarn-site.xml; do
    for f in slaves mapred-site.xml yarn-site.xml; do
      if [[ -e ${CONFIG_DIR}/$f ]]; then
        cp ${CONFIG_DIR}/$f $HADOOP_HOME/etc/hadoop/$f
      else
        echo "ERROR: Could not find $f in $CONFIG_DIR"
        exit 1
      fi
    done
    
    set -x
    cd /app/hdfs/bootstrap
    # Apply custom config file context
    for cfg in ./*; do
      if [[ ! "$cfg" =~ bootstrap.sh ]]; then
        echo $cfg
        cat $cfg
        cat $cfg > $HIVE_HOME/conf/${cfg##*/}
      fi
    done
    # Replace hive metadata password
    sed -i 's/${HIVE_METADATA_PASSWORD}/'$HIVE_METADATA_PASSWORD'/g' `grep '${HIVE_METADATA_PASSWORD}' -rl $HIVE_HOME/conf`
    # initSchema
    echo "step 1"
    if [[ ! -d $HIVE_HOME/log ]]; then
      mkdir $HIVE_HOME/log
    fi
    if [[ ! -e $HADOOP_CONF_DIR/hive-metastore-initialization.out ]]; then
      echo "step 2"
      $HADOOP_HOME/bin/hadoop fs -mkdir -p /tmp
      $HADOOP_HOME/bin/hadoop fs -mkdir -p /user/hive/warehouse
      $HADOOP_HOME/bin/hadoop fs -chmod g+w /tmp
      $HADOOP_HOME/bin/hadoop fs -chmod g+w /user/hive/warehouse
      $HIVE_HOME/bin/schematool -dbType mysql -initSchema --verbose &> $HIVE_HOME/log/hive-metastore-initialization.out
    fi
    echo "step 3"
    #$HIVE_HOME/bin/hiveserver2 2> $HIVE_HOME/log/hive-server2_stderr.log > $HIVE_HOME/log/hive-server2_stdout.log &
    $HIVE_HOME/bin/hive --service metastore 2> $HIVE_HOME/log/hive-metastore_stderr.log > $HIVE_HOME/log/hive-metastore_stdout.log &
    cp $HIVE_HOME/conf/hive-env.sh.template $HIVE_HOME/conf/hive-env.sh && echo "export HADOOP_CLIENT_OPTS=\"-Xmx512m -XX:MaxPermSize=1024m \$HADOOP_CLIENT_OPTS\"" >> $HIVE_HOME/conf/hive-env.sh
    # keep running
    sleep infinity
  hive-site.xml: |-
    <?xml version="1.0" encoding="UTF-8" standalone="no"?>
    <?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
    <configuration>
      <property>
        <name>javax.jdo.option.ConnectionUserName</name>
        <value>hive</value>
      </property>
      <property>
        <name>javax.jdo.option.ConnectionPassword</name>
        <value>${HIVE_METADATA_PASSWORD}</value>
      </property>
      <property>
        <name>javax.jdo.option.ConnectionURL</name>
        <value>jdbc:mysql://hive-metadata-mysql-service:3306/metastore?characterEncoding=utf8&amp;createDatabaseIfNotExist=true&amp;useSSL=false</value>
      </property>
      <property>
        <name>javax.jdo.option.ConnectionDriverName</name>
        <value>com.mysql.jdbc.Driver</value>
      </property>
      <property>
        <name>system:java.io.tmpdir</name>
        <value>/tmp</value>
      </property>
      <property>
        <name>system:user.name</name>
        <value>hive</value>
      </property>
      <property>
        <name>hive.server2.authentication</name>
        <value>NOSASL</value>
      </property>
      <property>
        <name>hive.metastore.schema.verification</name>
        <value>false</value>
      </property>
      <property>
        <name>datanucleus.fixedDatastore</name>
        <value>false</value>
      </property>
      <property>
        <name>datanucleus.autoCreateSchema</name>
        <value>true</value>
      </property>
      <property>
        <name>datanucleus.autoCreateTables</name>
        <value>true</value>
      </property>
      <property>
        <name>datanucleus.autoCreateColumns</name>
        <value>true</value>
      </property>
      <property>
        <name>datanucleus.schema.autoCreateAll</name>
        <value>true</value>
        <description>creates necessary schema on a startup if one doesn't exist. set this to false, after creating it once</description>
      </property>
    
      <property>
        <name>hive.optimize.sort.dynamic.partition</name>
        <value>true</value>
        <description>When enabled dynamic partitioning column will be globally sorted.
        This way we can keep only one record writer open for each partition value
        in the reducer thereby reducing the memory pressure on reducers.</description>
      </property>
      <property>
        <name>hive.exec.dynamic.partition.mode</name>
        <value>nostrict</value>
        <description>In strict mode, the user must specify at least one static partition in case the user accidentally overwrites all partitions.</description>
      </property>
    
    </configuration>
